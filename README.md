# SPEECH-EMOTION-RECOGNITIOn
Emotions play an integral role in our daily life, understanding a person's emotions will improve
human interactions, make conversations more enjoyable. In addition to using words, a speaker
communicates through body language, facial expressions, rhythm, and intonation. There are
many fields that can take advantage of knowing one's emotional state. For example, a
well-trained agent can identify an upset customer right away and direct them to another agent
who can monitor the conversation in real time and adjust. Our goal in this project is to
successfully detect emotions from a real time audio recording. We plan to use machine learning
and deep learning techniques like Random Forest, Support Vector Machines (SVM),
Convolution Neural Networks (CNN), Multi-Layer Perceptron classifier (MLP), Long
Short-Term Memory (LSTM) by implementing data preprocessing, feature extraction, hyper
parameter tuning.
We are planning to use two datasets RAVDESS (Ryerson Audio-Visual Database of Emotional
Speech and Song) and TESS (Toronto Emotional Speech Set). After scraping the official
websites of these datasets, we found that the RAVDESS dataset has 1440 speech files of 24
professional actors (12 Females, 12 males) in North American accent categorized into calm,
happy, sad, fearful, surprise, angry, disgust expressions. The TESS dataset has 2800 audio files
where a set of 200 words were spoken by 2 actresses aged 26 and 64 years.
